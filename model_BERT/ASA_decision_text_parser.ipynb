{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存到: /Users/niwenyu/Desktop/OCR_PDF_EXTRACT/work/parsed_decision.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_asa_decision(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # 获取文件名中的decision_id\n",
    "    decision_id = re.search(r'(\\d+)\\.txt$', file_path).group(1)\n",
    "    \n",
    "    # 定义需要提取的字段\n",
    "    fields = {\n",
    "        'complaint_number': r'COMPLAINT NUMBER\\s*(.*?)(?=\\n\\w)',\n",
    "        'advertiser': r'ADVERTISER\\s*(.*?)(?=\\n\\w)',\n",
    "        'advertisement': r'ADVERTISEMENT\\s*(.*?)(?=\\n\\w)',\n",
    "        'date_of_decision': r'DATE OF DECISION\\s*(.*?)(?=\\n\\w)',\n",
    "        'outcome': r'OUTCOME\\s*(.*?)(?=\\n\\w)',\n",
    "    }\n",
    "    \n",
    "    # 提取基本字段\n",
    "    data = {'decision_id': decision_id}\n",
    "    for field, pattern in fields.items():\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        if match:\n",
    "            data[field] = match.group(1).strip()\n",
    "        else:\n",
    "            data[field] = ''\n",
    "    \n",
    "    # 提取多行内容字段\n",
    "    # Complaint\n",
    "    complaint_match = re.search(r'Complaint:\\s*(.*?)(?=\\nRuling)', content, re.DOTALL)\n",
    "    if complaint_match:\n",
    "        complaint_text = complaint_match.group(1).strip()\n",
    "        complaint_text = ' '.join(line.strip() for line in complaint_text.split('\\n') if line.strip())\n",
    "        data['complaint'] = complaint_text\n",
    "    else:\n",
    "        data['complaint'] = ''\n",
    "    \n",
    "    # Ruling\n",
    "    ruling_match = re.search(r'Ruling\\s*(.*?)(?=\\nMore Information|Appeal Process)', content, re.DOTALL)\n",
    "    if ruling_match:\n",
    "        ruling_text = ruling_match.group(1).strip()\n",
    "        ruling_text = ' '.join(line.strip() for line in ruling_text.split('\\n') if line.strip())\n",
    "        data['ruling'] = ruling_text\n",
    "    else:\n",
    "        data['ruling'] = ''\n",
    "    \n",
    "    # Appeal Process\n",
    "    appeal_match = re.search(r'Appeal Process\\s*(.*?)$', content, re.DOTALL)\n",
    "    if appeal_match:\n",
    "        appeal_text = appeal_match.group(1).strip()\n",
    "        appeal_text = ' '.join(line.strip() for line in appeal_text.split('\\n') if line.strip())\n",
    "        data['appeal_process'] = appeal_text\n",
    "    else:\n",
    "        data['appeal_process'] = ''\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 处理单个文件并保存为CSV\n",
    "file_path = '/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/work/output/24/24006.txt'\n",
    "output_path = '/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/work/parsed_decision.csv'\n",
    "\n",
    "# 解析文件\n",
    "data = parse_asa_decision(file_path)\n",
    "\n",
    "# 创建DataFrame并设置列的顺序\n",
    "columns = ['decision_id', 'complaint_number', 'advertiser', 'advertisement', \n",
    "          'date_of_decision', 'outcome', 'complaint', 'ruling', 'appeal_process']\n",
    "df = pd.DataFrame([data])[columns]\n",
    "\n",
    "# 保存为CSV文件\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"文件已保存到: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 恶心人的复杂投诉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存到: parsed_decision_test.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_asa_decision(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # 获取文件名中的decision_id\n",
    "    decision_id = re.search(r'(\\d+)\\.txt$', file_path).group(1)\n",
    "    \n",
    "    # 基本字段提取\n",
    "    data = {\n",
    "        'decision_id': decision_id,\n",
    "        'complaint_number': extract_field(content, r'COMPLAINT NUMBER\\s*(.*?)(?=\\n\\w)'),\n",
    "        'advertiser': extract_field(content, r'ADVERTISER\\s*(.*?)(?=\\n\\w)'),\n",
    "        'advertisement': extract_field(content, r'ADVERTISEMENT\\s*(.*?)(?=\\n\\w)'),\n",
    "        'date_of_decision': extract_field(content, r'DATE OF (?:DECISION|MEETING)\\s*(.*?)(?=\\n\\w)'),\n",
    "        'outcome': extract_field(content, r'OUTCOME\\s*(.*?)(?=\\n\\w)')\n",
    "    }\n",
    "    \n",
    "    # 提取Summary部分\n",
    "    summary_match = re.search(r'Summary of the Complaints Board Decision\\s*(.*?)(?=\\n\\n\\w)', content, re.DOTALL)\n",
    "    if summary_match:\n",
    "        data['summary'] = clean_text(summary_match.group(1))\n",
    "    else:\n",
    "        data['summary'] = ''\n",
    "    \n",
    "    # 提取Complaint部分\n",
    "    complaint_match = re.search(r'Summary of the Complaint\\s*(.*?)(?=\\n\\nA copy of|Issues Raised)', content, re.DOTALL)\n",
    "    if complaint_match:\n",
    "        data['complaint'] = clean_text(complaint_match.group(1))\n",
    "    else:\n",
    "        # 尝试直接从Complaint部分提取\n",
    "        complaint_match = re.search(r'COMPLAINT\\s*(.*?)(?=\\n\\nAppendix)', content, re.DOTALL)\n",
    "        if complaint_match:\n",
    "            data['complaint'] = clean_text(complaint_match.group(1))\n",
    "        else:\n",
    "            data['complaint'] = ''\n",
    "    \n",
    "    # 提取Ruling/Decision部分\n",
    "    ruling_match = re.search(r'Complaints Board Discussion\\s*(.*?)(?=\\n\\nOutcome|APPEAL INFORMATION)', content, re.DOTALL)\n",
    "    if ruling_match:\n",
    "        data['ruling'] = clean_text(ruling_match.group(1))\n",
    "    else:\n",
    "        data['ruling'] = ''\n",
    "    \n",
    "    # 提取Appeal Information\n",
    "    appeal_match = re.search(r'APPEAL (?:PROCESS|INFORMATION)\\s*(.*?)(?=\\n\\nAPPENDICES|\\Z)', content, re.DOTALL)\n",
    "    if appeal_match:\n",
    "        data['appeal_process'] = clean_text(appeal_match.group(1))\n",
    "    else:\n",
    "        data['appeal_process'] = ''\n",
    "    \n",
    "    return data \n",
    "\n",
    "def extract_field(content, pattern):\n",
    "    \"\"\"提取单个字段的辅助函数\"\"\"\n",
    "    match = re.search(pattern, content, re.DOTALL)\n",
    "    return clean_text(match.group(1)) if match else ''\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"清理文本的辅助函数\"\"\"\n",
    "    # 删除多余的空白字符\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    # 删除多余的空行\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
    "    return text\n",
    "\n",
    "# 主程序\n",
    "def main(input_file, output_file):\n",
    "    # 解析文件\n",
    "    data = parse_asa_decision(input_file)\n",
    "    \n",
    "    # 创建DataFrame并设置列的顺序\n",
    "    columns = ['decision_id', 'complaint_number', 'advertiser', 'advertisement', \n",
    "              'date_of_decision', 'outcome', 'summary', 'complaint', 'ruling', \n",
    "              'appeal_process']\n",
    "    df = pd.DataFrame([data])[columns]\n",
    "    \n",
    "    # 保存为CSV文件\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"文件已保存到: {output_file}\")\n",
    "    return df\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/work/output/24/24005.txt'  # 替换为实际的输入文件路径\n",
    "    output_file = 'parsed_decision_test.csv'\n",
    "    df = main(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 针对24年的data处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def excel_to_csv(excel_file, csv_file):\n",
    "    \"\"\"\n",
    "    将 Excel 文件转换为 CSV，处理文本字段中的逗号\n",
    "    \n",
    "    Parameters:\n",
    "    excel_file (str): Excel 文件路径\n",
    "    csv_file (str): 输出 CSV 文件路径\n",
    "    \"\"\"\n",
    "    # 读取 Excel 文件\n",
    "    df = pd.read_excel(excel_file)\n",
    "    \n",
    "    # 将 DataFrame 写入 CSV，使用 csv 模块处理特殊字符\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        \n",
    "        # 写入表头\n",
    "        writer.writerow(df.columns)\n",
    "        \n",
    "        # 写入数据行\n",
    "        for _, row in df.iterrows():\n",
    "            # 将所有值转换为字符串\n",
    "            row_values = [str(value) for value in row]\n",
    "            writer.writerow(row_values)\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    excel_to_csv(\"/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/model_BERT/24_decision.xlsx\", \"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engine\n",
    "## 第一列修改\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据处理完成！结果已保存到 1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_complaint_numbers(df):\n",
    "    \"\"\"\n",
    "    处理投诉编号列，将形如 '24005.txt' 的格式转换为整数 24005\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): 包含投诉数据的 DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: 处理后的 DataFrame\n",
    "    \"\"\"\n",
    "    # 复制 DataFrame 以避免修改原始数据\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 提取第一列的数字部分并转换为整数\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].str.extract('(\\d+)').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main(input_file, output_file):\n",
    "    \"\"\"\n",
    "    主函数：读取 CSV 文件，处理数据，并保存结果\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): 输入 CSV 文件路径\n",
    "    output_file (str): 输出 CSV 文件路径\n",
    "    \"\"\"\n",
    "    # 读取 CSV 文件\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # 处理数据\n",
    "    df = process_complaint_numbers(df)\n",
    "    \n",
    "    # 保存处理后的数据\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"数据处理完成！结果已保存到 {output_file}\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/model_BERT/24_decision.csv\"   # 替换为你的输入文件路径\n",
    "    output_file = \"1.csv\" # 替换为你想要保存的输出文件路径\n",
    "    main(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取文件...\n",
      "正在处理数据...\n",
      "正在保存到原文件...\n",
      "\n",
      "数据类型转换后的信息:\n",
      "decision_id                  Int64\n",
      "complaint_number            object\n",
      "advertiser                  object\n",
      "advertisement               object\n",
      "date_of_meeting     datetime64[ns]\n",
      "outcome                     object\n",
      "complaint_id                 int64\n",
      "complaints                  object\n",
      "complaints_type             object\n",
      "len_complaint                int64\n",
      "adver_id                     Int64\n",
      "adver                       object\n",
      "adver_tyoe                 float64\n",
      "ttarr(i)_adver              object\n",
      "len_adver                    int64\n",
      "dtype: object\n",
      "\n",
      "complaints_type唯一值:\n",
      "['Unknown']\n",
      "\n",
      "处理完成！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "# 定义枚举类\n",
    "class ComplaintType(Enum):\n",
    "    UNKNOWN = \"Unknown\"\n",
    "    # 示例类型，后续可添加具体类别\n",
    "    TYPE_A = \"Type A\"\n",
    "    TYPE_B = \"Type B\"\n",
    "    TYPE_C = \"Type C\"\n",
    "\n",
    "class AdvertType(Enum):\n",
    "    UNKNOWN = \"Unknown\"\n",
    "    # 示例类型，后续可添加具体类别\n",
    "    TYPE_1 = \"Type 1\"\n",
    "    TYPE_2 = \"Type 2\"\n",
    "    TYPE_3 = \"Type 3\"\n",
    "\n",
    "def convert_to_enum(value, enum_class):\n",
    "    \"\"\"转换值为枚举类型\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return enum_class.UNKNOWN.value\n",
    "    \n",
    "    try:\n",
    "        # 尝试直接匹配枚举值\n",
    "        return enum_class[str(value).upper()].value\n",
    "    except:\n",
    "        return enum_class.UNKNOWN.value\n",
    "\n",
    "def clean_and_convert_data(df):\n",
    "    \"\"\"\n",
    "    清理CSV数据并转换数据类型\n",
    "    \n",
    "    参数:\n",
    "    df (pandas.DataFrame): 输入的数据框\n",
    "    \n",
    "    返回:\n",
    "    pandas.DataFrame: 处理后的数据框\n",
    "    \"\"\"\n",
    "    # 复制DataFrame以避免修改原始数据\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 第一步：处理逗号\n",
    "    def escape_commas(text):\n",
    "        \"\"\"处理文本中的逗号\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return text\n",
    "        return str(text).replace(',', '|')\n",
    "    \n",
    "    # 处理complaints和adver列的逗号\n",
    "    for col in ['complaints', 'adver']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = df_clean[col].apply(escape_commas)\n",
    "    \n",
    "    # 第二步：转换数据类型\n",
    "    # 转换decision_id为int\n",
    "    df_clean['decision_id'] = pd.to_numeric(df_clean['decision_id'], errors='coerce').astype('Int64')\n",
    "    df_clean['adver_id'] = pd.to_numeric(df_clean['adver_id'], errors= 'coerce' ).astype('Int64')\n",
    "    # 确保complaint_number为字符串\n",
    "    df_clean['complaint_number'] = df_clean['complaint_number'].astype(str)\n",
    "    \n",
    "    # 确保advertiser和advertisement为字符串\n",
    "    df_clean['advertiser'] = df_clean['advertiser'].fillna('').astype(str)\n",
    "    df_clean['advertisement'] = df_clean['advertisement'].fillna('').astype(str)\n",
    "    \n",
    "    # 转换date_of_meeting为日期格式\n",
    "    def convert_date(date_str):\n",
    "        if pd.isna(date_str):\n",
    "            return None\n",
    "        try:\n",
    "            formats = ['%Y-%m-%d', '%d-%b-%Y', '%Y-%m-%d %H:%M:%S', \n",
    "                      '%d %B %Y', '%B %Y', '%d %b %Y']\n",
    "            for fmt in formats:\n",
    "                try:\n",
    "                    return pd.to_datetime(date_str, format=fmt)\n",
    "                except:\n",
    "                    continue\n",
    "            return pd.to_datetime(date_str)\n",
    "        except:\n",
    "            return None\n",
    "            \n",
    "    df_clean['date_of_meeting'] = df_clean['date_of_meeting'].apply(convert_date)\n",
    "    \n",
    "    # 转换complaints_type为枚举类型\n",
    "    if 'complaints_type' in df_clean.columns:\n",
    "        df_clean['complaints_type'] = df_clean['complaints_type'].apply(\n",
    "            lambda x: convert_to_enum(x, ComplaintType)\n",
    "        )\n",
    "    \n",
    "    # 转换adver_type为枚举类型（更正拼写错误后的列名）\n",
    "    if 'adver_type' in df_clean.columns:\n",
    "        df_clean['adver_type'] = df_clean['adver_type'].apply(\n",
    "            lambda x: convert_to_enum(x, AdvertType)\n",
    "        )\n",
    "    \n",
    "    # 计算len_complaint（统计complaints列字数）\n",
    "    df_clean['len_complaint'] = df_clean['complaints'].fillna('').str.len()\n",
    "    \n",
    "    # 计算len_adver（统计adver列字数）\n",
    "    df_clean['len_adver'] = df_clean['adver'].fillna('').str.len()\n",
    "    \n",
    "    # 删除原来的len(adver)列（如果存在）\n",
    "    if 'len(adver)' in df_clean.columns:\n",
    "        df_clean = df_clean.drop('len(adver)', axis=1)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 读取并处理文件\n",
    "        print(\"正在读取文件...\")\n",
    "        df = pd.read_csv('/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/model_BERT/test_1.csv')\n",
    "        \n",
    "        print(\"正在处理数据...\")\n",
    "        df_cleaned = clean_and_convert_data(df)\n",
    "        \n",
    "        # 保存回原文件\n",
    "        print(\"正在保存到原文件...\")\n",
    "        df_cleaned.to_csv('/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/model_BERT/test_1.csv', index=False)\n",
    "        \n",
    "        # 打印数据类型信息\n",
    "        print(\"\\n数据类型转换后的信息:\")\n",
    "        print(df_cleaned.dtypes)\n",
    "        \n",
    "        # 打印枚举类型列的唯一值\n",
    "        if 'complaints_type' in df_cleaned.columns:\n",
    "            print(\"\\ncomplaints_type唯一值:\")\n",
    "            print(df_cleaned['complaints_type'].unique())\n",
    "        \n",
    "        if 'adver_type' in df_cleaned.columns:\n",
    "            print(\"\\nadver_type唯一值:\")\n",
    "            print(df_cleaned['adver_type'].unique())\n",
    "        \n",
    "        print(\"\\n处理完成！\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出现错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete! The updated DataFrame has been saved to: test_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 输入和输出文件路径（请根据实际情况修改）\n",
    "input_csv = '/Users/niwenyu/Desktop/OCR_PDF_EXTRACT/processed_24_1 copy.csv'\n",
    "output_csv = 'test_1.csv'\n",
    "\n",
    "# 1. 从CSV文件读入数据\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# 确保有 'adver' 列\n",
    "if 'adver' not in df.columns:\n",
    "    raise ValueError(\"The input CSV file must contain an 'adver' column.\")\n",
    "\n",
    "# 2. 筛选出 adver 不为空的行\n",
    "df_fill = df[~df['adver'].isna() & (df['adver'] != '')].copy()\n",
    "\n",
    "# 3. 在df_fill中为adver_id赋值\n",
    "df_fill['adver_id'] = np.nan\n",
    "prev_adver = None\n",
    "prev_index = None\n",
    "current_id = 24000  # 初始值：下一条新adver将使用24001开始\n",
    "\n",
    "for i in df_fill.index:\n",
    "    current_adver = df_fill.loc[i, 'adver']\n",
    "    if prev_adver is None:\n",
    "        # 第一条非空的adver\n",
    "        current_id += 1  # current_id = 24001\n",
    "        df_fill.loc[i, 'adver_id'] = current_id\n",
    "    else:\n",
    "        if current_adver == prev_adver:\n",
    "            # 与上一条adver相同\n",
    "            df_fill.loc[i, 'adver_id'] = df_fill.loc[prev_index, 'adver_id']\n",
    "        else:\n",
    "            # 与上一条adver不同\n",
    "            df_fill.loc[i, 'adver_id'] = df_fill.loc[prev_index, 'adver_id'] + 1\n",
    "\n",
    "    prev_adver = current_adver\n",
    "    prev_index = i\n",
    "\n",
    "# 4. 将df_fill中的adver_id映射回df\n",
    "if 'adver_id' not in df.columns:\n",
    "    df['adver_id'] = np.nan\n",
    "\n",
    "# 利用索引对齐，将df_fill的adver_id赋回df\n",
    "df.loc[df_fill.index, 'adver_id'] = df_fill['adver_id']\n",
    "\n",
    "# 5. 将结果保存到新的CSV文件\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"Processing complete! The updated DataFrame has been saved to:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "778_python3.10_cuda11.3_torch1.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
