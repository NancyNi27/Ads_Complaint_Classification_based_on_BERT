{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/p2gkv4651zl5pzcfg3b974_h0000gn/T/ipykernel_54370/4139675818.py:202: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(self.model_dir / 'pytorch_model.pt',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'request_id': '8c3fe0b8-5d8a-4975-adab-079b6359cafa', 'status': 'success', 'timestamp': '2025-02-03T11:42:11.199579', 'data': {'analysis_results': [{'category': 'misleading', 'confidence': 0.9996662139892578}, {'category': 'social responsibility', 'confidence': 0.00021386801381595433}, {'category': 'placement', 'confidence': 8.297273598145694e-05}, {'category': 'other', 'confidence': 2.5500661649857648e-05}], 'metadata': {'model_version': 'hybrid-bert-base-v1.0', 'language': 'eng', 'word_count': 9}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModelConfig:\n",
    "    def __init__(self, config_path):\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        # 基本配置\n",
    "        self.model_type = config.get('model_type', 'hybrid-bert')\n",
    "        self.bert_base_model = config.get('bert_base_model', 'bert-base-uncased')\n",
    "        self.hidden_size = config.get('hidden_size', 768)\n",
    "        self.n_classes = config.get('n_classes', 6)\n",
    "        self.n_features = config.get('n_features', 46)\n",
    "        self.combined_dim = config.get('combined_dim', 814)\n",
    "        self.model_version = config.get('model_version', 'hybrid-bert-base-v1.0')\n",
    "        self.max_length = config.get('max_length', 512)  # 添加 max_length 参数\n",
    "        \n",
    "        # 分类器配置\n",
    "        classifier_config = config.get('classifier_config', {})\n",
    "        self.hidden_layers = classifier_config.get('hidden_layers', [512, 256])\n",
    "        self.dropout = classifier_config.get('dropout', 0.3)\n",
    "        self.output_dim = classifier_config.get('output_dim', 6)\n",
    "        \n",
    "        # 设备配置\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class FeatureConfig:\n",
    "    def __init__(self, config_path):\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        self.label_dict = config.get('label_dict', {})\n",
    "        self.emotion_words = config.get('emotion_words', {})\n",
    "\n",
    "class ImprovedAdComplaintFeatures:\n",
    "    def __init__(self, feature_config):\n",
    "        self.label_dict = feature_config.label_dict\n",
    "        self.emotion_words = feature_config.emotion_words\n",
    "\n",
    "    # [Previous methods remain the same]\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"文本清理\"\"\"\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s!?.,-:;\\'\"()]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_phrase_features(self, text, phrases):\n",
    "        \"\"\"提取短语特征\"\"\"\n",
    "        count = 0\n",
    "        for phrase in phrases:\n",
    "            count += text.count(phrase)\n",
    "        return count\n",
    "\n",
    "    def extract_label_features(self, text):\n",
    "        \"\"\"提取标签相关特征\"\"\"\n",
    "        text = self.clean_text(text)\n",
    "        words = text.split()\n",
    "        total_words = len(words) if words else 1\n",
    "\n",
    "        features = {}\n",
    "        \n",
    "        for label, word_sets in self.label_dict.items():\n",
    "            primary_count = sum(word in text for word in word_sets['primary'])\n",
    "            phrase_count = self.extract_phrase_features(text, word_sets['phrases'])\n",
    "            \n",
    "            features.update({\n",
    "                f'{label}_primary_count': primary_count,\n",
    "                f'{label}_phrase_count': phrase_count,\n",
    "                f'{label}_total_count': primary_count + phrase_count,\n",
    "                f'{label}_density': (primary_count + phrase_count) / total_words,\n",
    "                f'{label}_phrase_ratio': phrase_count / (primary_count + phrase_count + 1e-10)\n",
    "            })\n",
    "\n",
    "        return features\n",
    "\n",
    "    def extract_emotion_features(self, text):\n",
    "        \"\"\"提取情感特征\"\"\"\n",
    "        text = self.clean_text(text)\n",
    "        words = text.split()\n",
    "        total_words = len(words) if words else 1\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "\n",
    "        features = {}\n",
    "\n",
    "        for emotion, words_list in self.emotion_words.items():\n",
    "            count = sum(word in text for word in words_list)\n",
    "            features[f'{emotion}_count'] = count\n",
    "            features[f'{emotion}_ratio'] = count / total_words\n",
    "\n",
    "        features.update({\n",
    "            'exclamation_density': text.count('!') / len(sentences) if sentences else 0,\n",
    "            'question_density': text.count('?') / len(sentences) if sentences else 0,\n",
    "            'emphasis_punctuation': (text.count('!') + text.count('?')) / len(sentences) if sentences else 0,\n",
    "            'caps_sentence_ratio': sum(1 for s in sentences if any(c.isupper() for c in s)) / len(sentences) if sentences else 0\n",
    "        })\n",
    "\n",
    "        return features\n",
    "\n",
    "    def extract_structural_features(self, text):\n",
    "        \"\"\"提取结构特征\"\"\"\n",
    "        text = str(text)\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        words = text.split()\n",
    "\n",
    "        return {\n",
    "            'sentence_count': len(sentences),\n",
    "            'avg_sentence_length': np.mean([len(s.split()) for s in sentences]) if sentences else 0,\n",
    "            'max_sentence_length': max([len(s.split()) for s in sentences]) if sentences else 0,\n",
    "            'min_sentence_length': min([len(s.split()) for s in sentences]) if sentences else 0,\n",
    "            'word_count': len(words),\n",
    "            'unique_word_ratio': len(set(words)) / len(words) if words else 0,\n",
    "            'comma_per_sentence': sum(s.count(',') for s in sentences) / len(sentences) if sentences else 0\n",
    "        }\n",
    "\n",
    "    def create_features_single_text(self, text):\n",
    "        \"\"\"为单个文本创建所有特征\"\"\"\n",
    "        features = {}\n",
    "        features.update(self.extract_label_features(text))\n",
    "        features.update(self.extract_emotion_features(text))\n",
    "        features.update(self.extract_structural_features(text))\n",
    "\n",
    "        for i in range(6):\n",
    "            features[f'keyword_match_{i}'] = 0\n",
    "\n",
    "        feature_names = sorted(features.keys())\n",
    "        feature_vector = np.array([features[name] for name in feature_names])\n",
    "        \n",
    "        return feature_vector\n",
    "\n",
    "class HybridBERTModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(config.bert_base_model)\n",
    "        \n",
    "        # Load from config\n",
    "        self.n_classes = config.n_classes\n",
    "        self.combined_dim = config.combined_dim\n",
    "        \n",
    "        # 构建分类器层\n",
    "        layers = []\n",
    "        input_dim = self.combined_dim\n",
    "        \n",
    "        # 添加隐藏层\n",
    "        for hidden_dim in config.hidden_layers:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(config.dropout)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # 添加输出层\n",
    "        layers.extend([\n",
    "            nn.Linear(input_dim, config.output_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        ])\n",
    "        \n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, features):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output.pooler_output\n",
    "        combined_features = torch.cat((pooled_output, features), dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n",
    "class InferenceEngine:\n",
    "    def __init__(self, model_dir):\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.config = ModelConfig(self.model_dir / 'config.json')\n",
    "        self.feature_config = FeatureConfig(self.model_dir / 'feature_config.json')\n",
    "        \n",
    "        # Initialize components\n",
    "        self.tokenizer = self._load_tokenizer()\n",
    "        self.feature_engineer = ImprovedAdComplaintFeatures(self.feature_config)\n",
    "        self.model = self._load_model()\n",
    "        self.scaler = self._initialize_scaler()\n",
    "        \n",
    "    def _load_tokenizer(self):\n",
    "        \"\"\"Load tokenizer from local files\"\"\"\n",
    "        tokenizer_files = {\n",
    "            'vocab_file': str(self.model_dir / 'vocab.txt'),\n",
    "            'special_tokens_map_file': str(self.model_dir / 'special_tokens_map.json'),\n",
    "            'tokenizer_config_file': str(self.model_dir / 'tokenizer_config.json')\n",
    "        }\n",
    "        return BertTokenizer.from_pretrained(str(self.model_dir), **tokenizer_files)\n",
    "        \n",
    "    def _load_model(self):\n",
    "        model = HybridBERTModel(self.config)\n",
    "        model.load_state_dict(torch.load(self.model_dir / 'pytorch_model.pt', \n",
    "                                       map_location=self.config.device))\n",
    "        model.to(self.config.device)\n",
    "        model.eval()\n",
    "        return model\n",
    "        \n",
    "    def _initialize_scaler(self):\n",
    "        scaler = StandardScaler()\n",
    "        sample_features = self.feature_engineer.create_features_single_text(\"Sample text\")\n",
    "        scaler.fit(sample_features.reshape(1, -1))\n",
    "        return scaler\n",
    "        \n",
    "    def analyze_text(self, text):\n",
    "        try:\n",
    "            # Create features\n",
    "            features = self.feature_engineer.create_features_single_text(text)\n",
    "            features_scaled = self.scaler.transform(features.reshape(1, -1))\n",
    "            \n",
    "            # Tokenize\n",
    "            encoding = self.tokenizer(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.config.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Move to device\n",
    "            input_ids = encoding['input_ids'].to(self.config.device)\n",
    "            attention_mask = encoding['attention_mask'].to(self.config.device)\n",
    "            features = torch.FloatTensor(features_scaled).to(self.config.device)\n",
    "            \n",
    "            # Get prediction\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_ids, attention_mask, features)\n",
    "                predictions = outputs.cpu().numpy()[0]\n",
    "            \n",
    "            # Process results\n",
    "            category_mapping = {\n",
    "                0: \"misleading\",\n",
    "                1: \"social responsibility\",\n",
    "                2: \"placement\",\n",
    "                3: \"children issues\",\n",
    "                4: \"taste and decency\",\n",
    "                5: \"other\"\n",
    "            }\n",
    "            \n",
    "            top_indices = np.argsort(predictions)[-4:][::-1]\n",
    "            analysis_results = [\n",
    "                {\n",
    "                    \"category\": category_mapping[idx],\n",
    "                    \"confidence\": float(predictions[idx])\n",
    "                }\n",
    "                for idx in top_indices\n",
    "            ]\n",
    "            \n",
    "            return {\n",
    "                \"request_id\": str(uuid.uuid4()),\n",
    "                \"status\": \"success\",\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"data\": {\n",
    "                    \"analysis_results\": analysis_results,\n",
    "                    \"metadata\": {\n",
    "                        \"model_version\": self.config.model_version,\n",
    "                        \"language\": \"eng\",\n",
    "                        \"word_count\": len(text.split())\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error analyzing text: {str(e)}\")\n",
    "            return {\n",
    "                \"request_id\": str(uuid.uuid4()),\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    MODEL_DIR = \"model_files\"\n",
    "    \n",
    "    # Initialize inference engine\n",
    "    engine = InferenceEngine(MODEL_DIR)\n",
    "    \n",
    "    # Test text\n",
    "    test_text = \"Seen at the Coromandel Ketic Fair on 2 January...\"\n",
    "    \n",
    "    # Get analysis results\n",
    "    result = engine.analyze_text(test_text)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "778_python3.10_cuda11.3_torch1.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
