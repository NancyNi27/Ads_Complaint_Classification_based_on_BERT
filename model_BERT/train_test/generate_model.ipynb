{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hw/p2gkv4651zl5pzcfg3b974_h0000gn/T/ipykernel_53931/2784519716.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('../best_model/best_hybrid_model_fold_5.pt', map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json has been generated in model_files directory\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_config():\n",
    "    # 确保在model_files目录下\n",
    "    os.makedirs('model_files', exist_ok=True)\n",
    "\n",
    "    # 只从第5个模型文件获取特征数量\n",
    "    state_dict = torch.load('../best_model/best_hybrid_model_fold_5.pt', map_location='cpu')\n",
    "    n_features = state_dict['classifier.0.weight'].shape[1] - 768\n",
    "\n",
    "    # 创建配置\n",
    "    config = {\n",
    "        \"architectures\": [\"HybridBERTModel\"],\n",
    "        \"model_type\": \"hybrid-bert\",\n",
    "        # 基础配置\n",
    "        \"bert_base_model\": \"bert-base-uncased\",\n",
    "        \"hidden_size\": 768,\n",
    "        # 模型特定配置\n",
    "        \"n_classes\": 6,\n",
    "        \"n_features\": n_features,\n",
    "        \"combined_dim\": 768 + n_features,\n",
    "        # 分类器配置\n",
    "        \"classifier_config\": {\n",
    "            \"hidden_layers\": [512, 256],\n",
    "            \"dropout\": 0.3,\n",
    "            \"output_dim\": 6\n",
    "        },\n",
    "        # 版本信息\n",
    "        \"model_version\": \"hybrid-bert-base-v1.0\"\n",
    "    }\n",
    "\n",
    "    # 保存配置\n",
    "    with open('config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "    \n",
    "    print(\"config.json has been generated in model_files directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已生成在 model_files 目录中\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "def generate_all_files():\n",
    "    # 创建目录\n",
    "    os.makedirs('model_files', exist_ok=True)\n",
    "    \n",
    "    # 1. 生成feature_config.json\n",
    "    # 从你的代码中的ImprovedAdComplaintFeatures类获取配置\n",
    "    feature_config = {\n",
    "        \"label_dict\": {\n",
    "            'misleading': {\n",
    "                'primary': [\n",
    "                    'misleading', 'false', 'incorrect', 'inaccurate', 'untrue',\n",
    "                    'deceptive', 'misrepresent', 'exaggerate', 'misleads',\n",
    "                    'unsubstantiated', 'wrong', 'dishonest', 'no proof'\n",
    "                ],\n",
    "                'phrases': [\n",
    "                    'not true', 'false claim', 'misleading information',\n",
    "                    'wrong information', 'cannot be substantiated'\n",
    "                ]\n",
    "            },\n",
    "            'social_responsibility': {\n",
    "                'primary': [\n",
    "                    'unsafe', 'dangerous', 'harmful', 'irresponsible', 'hazard',\n",
    "                    'risk', 'safety', 'health', 'alcohol', 'gambling'\n",
    "                ],\n",
    "                'phrases': [\n",
    "                    'social responsibility', 'public safety', 'health risk',\n",
    "                    'safety concern', 'unsafe practice'\n",
    "                ]\n",
    "            },\n",
    "            'placement': {\n",
    "                'primary': [\n",
    "                    'location', 'place', 'position', 'display', 'billboard',\n",
    "                    'visible', 'screen', 'site', 'area', 'distance'\n",
    "                ],\n",
    "                'phrases': [\n",
    "                    'near school', 'close to', 'in front of', 'next to',\n",
    "                    'wrong place'\n",
    "                ]\n",
    "            },\n",
    "            'children': {\n",
    "                'primary': [\n",
    "                    'child', 'children', 'kid', 'minor', 'young', 'youth',\n",
    "                    'teen', 'teenage', 'student', 'school', 'parent'\n",
    "                ],\n",
    "                'phrases': [\n",
    "                    'target children', 'appeal to children', 'child safety',\n",
    "                    'protect children', 'school area'\n",
    "                ]\n",
    "            },\n",
    "            'taste_decency': {\n",
    "                'primary': [\n",
    "                    'offensive', 'inappropriate', 'vulgar', 'explicit', 'sexual',\n",
    "                    'violent', 'disturbing', 'graphic', 'crude', 'tasteless'\n",
    "                ],\n",
    "                'phrases': [\n",
    "                    'sexually suggestive', 'offensive content', 'bad taste',\n",
    "                    'inappropriate content', 'adult content'\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"emotion_words\": {\n",
    "            'strong_negative': [\n",
    "                'very', 'extremely', 'absolutely', 'totally', 'completely',\n",
    "                'highly', 'seriously', 'strongly', 'deeply', 'gravely'\n",
    "            ],\n",
    "            'concern': [\n",
    "                'worry', 'concern', 'afraid', 'fear', 'alarming',\n",
    "                'dangerous', 'risky', 'threat', 'problem', 'issue'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('model_files/feature_config.json', 'w') as f:\n",
    "        json.dump(feature_config, f, indent=4)\n",
    "    \n",
    "    # 2. 复制模型权重文件\n",
    "    shutil.copy('../best_model/best_hybrid_model_fold_5.pt', 'model_files/pytorch_model.pt')\n",
    "    \n",
    "    # 3. 获取tokenizer相关文件\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenizer.save_pretrained('./model_files')\n",
    "    # 这会自动生成 vocab.txt, tokenizer.json 和 tokenizer_config.json\n",
    "    \n",
    "    print(\"所有文件已生成在 model_files 目录中\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "778_python3.10_cuda11.3_torch1.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
